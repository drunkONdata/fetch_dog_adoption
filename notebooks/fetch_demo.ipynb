{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from keras.models import load_model\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.spatial import distance\n",
    "import random\n",
    "import time\n",
    "import urllib.request\n",
    "import io\n",
    "#import glob\n",
    "#from src.fetch_data_pipeline import extract_image_url, extract_df, download_images, load_RG_data, zip_lookup, gps_lookup\n",
    "#import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "feature_matrix = np.load('/Users/bil2ab/fetch_vectors_backup/fetch_feature_matrix.npy')\n",
    "vector_list = pd.read_pickle('/Users/bil2ab/fetch_vectors_backup/fetch_vector_list.pkl', compression='gzip')\n",
    "end = time.time()\n",
    "print('Fetch Feature Matrix loaded.  Time: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = vgg16.VGG16(include_top = True, weights = 'imagenet')\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.outputs = [model.layers[-1].output]\n",
    "end = time.time()\n",
    "print('Neural Network initialized.  Time: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "#yaml_model = model.to_yaml()\n",
    "#del model  # deletes the existing model\n",
    "#end = time.time()\n",
    "#print('Neural Network saved as YAML.  Time: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#start = time.time()\n",
    "#model = load_model('test_model.h5')\n",
    "#end = time.time()\n",
    "#print('Neural Network loaded.  Time: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_a = '../data/images/hanna_PuPPy.jpg'\n",
    "#filename_a = 'data/test1.png'\n",
    "#filename_a = 'data/test2.png'\n",
    "#filename_a = 'data/test3.png'\n",
    "#filename_a = 'data/mossy1.png'\n",
    "#filename_a = 'data/Nibu.png'\n",
    "#filename_a = 'data/dyno.png'\n",
    "#filename_a = 'data/cool.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "original_a = load_img(filename_a, target_size=(224, 224))\n",
    "print('PIL image size', original_a.size)\n",
    "plt.imshow(original_a)\n",
    "plt.show()\n",
    " \n",
    "# Convert image to numpy array\n",
    "# PIL - image (w, h, channel)  desxxNumpy - image (h, w, channel)\n",
    "numpy_image_a = img_to_array(original_a)\n",
    "plt.imshow(np.uint8(numpy_image_a))\n",
    "plt.show()\n",
    "print('numpy array size',numpy_image_a.shape)\n",
    " \n",
    "# Convert the image into batch format\n",
    "# expand_dims will add an extra dimension to the data at a particular axis\n",
    "# We want the input matrix to the network to be of the form (batchsize, height, width, channels)\n",
    "# Thus we add the extra dimension to the axis 0.\n",
    "image_batch_a = np.expand_dims(numpy_image_a, axis=0)\n",
    "print('image batch size', image_batch_a.shape)\n",
    "plt.imshow(np.uint8(image_batch_a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the image for the VGG model\n",
    "processed_image_a = vgg16.preprocess_input(image_batch_a.copy())\n",
    "\n",
    "# get the predicted probabilities for each class\n",
    "predictions_a = model.predict(processed_image_a)\n",
    "\n",
    "print(predictions_a)\n",
    "print(len(predictions_a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for vector in vector_list:\n",
    "    labels.append(vector[12:].split('.')[0]+'.jpg')\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "score_cos = distance.cdist(predictions_a, feature_matrix, 'cosine').tolist()\n",
    "end = time.time()\n",
    "print('Cosine Similarity with SciPy calculated.  Time: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if len(labels) != len(score[0]):\n",
    "#    print('Length mismatch!')\n",
    "\n",
    "sorted_scores = sorted(list(zip(labels,score_cos[0])), key = lambda t: t[1])\n",
    "    \n",
    "for image, score in sorted_scores[0:20]:\n",
    "    url = 'https://s3-us-west-2.amazonaws.com/hole-in-a-bucket/data/'+image\n",
    "    im = Image.open(requests.get(url, stream=True).raw)\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 - Random\n",
    "\n",
    "for x in range(0,10):\n",
    "    img_name = random.choice(vector_list)[12:].split('.')[0]+'.jpg'\n",
    "    url ='https://s3-us-west-2.amazonaws.com/hole-in-a-bucket/data/'+img_name\n",
    "    im = Image.open(requests.get(url, stream=True).raw)\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_list = pd.read_pickle('data/fetch_vector_list.pkl', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_test = np.load('data/feature_matrix/fetch_feature_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "idx = 35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if idx>0 and idx<140741:\n",
    "    print(str(idx)+' vectors merged to feature matrix.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if idx%1000 == 0:\n",
    "    print(str(idx)+' vectors merged to feature matrix.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(0,5678,4096)\n",
    "b = np.linspace(340,678,4096)\n",
    "c = np.linspace(40,834789,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as scs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-scs.binom(353, 0.5).cdf(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_matches(labels,score):\n",
    "    sorted_scores = sorted(list(zip(labels.tolist(),score)), key = lambda t: t[1])\n",
    "    return sorted_scores[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df, combined_imgs = load_RG_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image file name, store in Pandas Series and pickle for website\n",
    "image_names = []\n",
    "for image_url in combined_imgs.ImageUrl[0:140741]:\n",
    "        image_names.append(image_url.split('/')[-1])\n",
    "\n",
    "fetch_image_names = pd.Series(image_names)\n",
    "fetch_image_names.to_pickle('data/fetch_img_urls.pkl', compression='gzip')\n",
    "\n",
    "\n",
    "\n",
    "#combined_df.head()\n",
    "#zipped_dogs = list(zip(dog_url.tolist(),results))\n",
    "#sorted_zipped_dogs = sorted(zipped_dogs, key = lambda t: t[1])\n",
    "#top_10 = sorted_zipped_dogs[0:11]\n",
    "#top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load NumPy data file of 4750 dogs and calculate average number of non-zero features in 1D arrays for all dogs\n",
    "\n",
    "non_zero_features = []\n",
    "feature_array_4750 = np.load('web/static/temp/data/doggie_features_4750.npy')\n",
    "\n",
    "for dog in feature_array_4750:\n",
    "    non_zero_features.append(len(np.where(dog>0)[1]))\n",
    "\n",
    "plt.hist(non_zero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scores in score_lists:\n",
    "    for image,score in top_ten(dog_url, scores):\n",
    "        plt.imshow(load_img('/Users/bil2ab/galvanize/RG5kimages/'+image.split('/')[-1]))\n",
    "        plt.show()\n",
    "        #print(1-score)\n",
    "        #print('DURKA DURKA...next distance metric:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    start = time.time()\n",
    "    feature_array_list = []\n",
    "    #image_path_list formerly combined_df.ImageUrl[0:4750]\n",
    "    for url in image_path_list[0:length]:\n",
    "        image_path = '/Users/bil2ab/galvanize/capstone/images_to_vectorize/images/'+url.split('/')[-1]\n",
    "        dog = load_img(image_path, target_size=(224, 224))\n",
    "        numpy_image = img_to_array(dog)\n",
    "        image_batch = np.expand_dims(numpy_image, axis=0)  \n",
    "        processed_image = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_array = model.predict(processed_image)\n",
    "        feature_array_list.append(feature_array)\n",
    "        #doggie = np.asarray(feature_array_list)\n",
    "        #np.save('data/RG_50k_features', doggie)\n",
    "    end = time.time()\n",
    "    total_time = end-start\n",
    "    print('Total Time: '+str(total_time))\n",
    "    print('All dog features vectorized!')\n",
    "    return feature_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url_vec = combined_imgs.ImageUrl.tolist()\n",
    "holy_durka = vectorize_dog_images(url_vec, length=50000)\n",
    "#len(url_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def durka():\n",
    "    '''\n",
    "    image_path_list = combined_df.ImageUrl.tolist()\n",
    "    Take collection of dog images and vectorize each image to a 1D NumPy array. \n",
    "    INPUT: List, Pandas Series, some iterable of filepaths to dog images (strings)\n",
    "    OUTPUT: Returns Numpy data file\n",
    "    '''\n",
    "    start = time.time()\n",
    "    combined_df, combined_imgs = load_RG_data()\n",
    "    #num_images = len(glob.glob1('/Users/bil2ab/galvanize/RG5kimages/','*.jpg'))\n",
    "    image_path_list = combined_imgs.ImageUrl.tolist()\n",
    "    feature_matrix = np.zeros((len(image_path_list),4096))\n",
    "    \n",
    "    for idx,url in enumerate(image_path_list):\n",
    "        dog = load_img('/Users/bil2ab/galvanize/RG5kimages/'+url.split('/')[-1], target_size=(224, 224))\n",
    "        image_batch = np.expand_dims(img_to_array(dog), axis=0)  \n",
    "        processed_image = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_matrix[idx] = model.predict(processed_image)\n",
    "    \n",
    "    #Save csv of image urls\n",
    "    image_path_list.to_csv('/data/dog_urls_test.csv')\n",
    "    \n",
    "    #Save list of feature arrays as numpy data file\n",
    "    #doggie = np.asarray(feature_array_list)\n",
    "    np.save('/data/doggie_features_test', feature_matrix)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Total Time: '+str(end-start))\n",
    "    print('All dog features vectorized!')\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the VGG model\n",
    "#vgg_model = vgg16.VGG16(weights='imagenet')\n",
    "\n",
    "#Load the Inception_V3 model\n",
    "#inception_model = inception_v3.InceptionV3(weights='imagenet')\n",
    " \n",
    "#Load the ResNet50 model\n",
    "#resnet_model = resnet50.ResNet50(weights='imagenet')\n",
    " \n",
    "#Load the MobileNet model\n",
    "#mobilenet_model = mobilenet.MobileNet(weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract exif data from smartphone image and view in nice format\n",
    "\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "#def extract_image_data(file):\n",
    "filename =''\n",
    "im = PIL.Image.open(filename)\n",
    "exifdict = im._getexif()\n",
    "#print(exifdict)\n",
    "\n",
    "if len(exifdict):\n",
    "    for k in exifdict.keys():\n",
    "        if k in TAGS.keys():\n",
    "            print(TAGS[k], exifdict[k])\n",
    "        else:\n",
    "            print(k, exifdict[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
