{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from keras.models import load_model\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.spatial import distance\n",
    "import random\n",
    "import time\n",
    "import urllib.request\n",
    "import io\n",
    "#import glob\n",
    "from src.fetch_data_pipeline import extract_image_url, extract_df, download_images, load_RG_data, zip_lookup, gps_lookup\n",
    "#import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetch Feature Matrix loaded.  Time: 25.39776587486267\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "feature_matrix = np.load('/Users/bil2ab/fetch_vectors_backup/fetch_feature_matrix.npy')\n",
    "vector_list = pd.read_pickle('/Users/bil2ab/fetch_vectors_backup/fetch_vector_list.pkl', compression='gzip')\n",
    "end = time.time()\n",
    "print('Fetch Feature Matrix loaded.  Time: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network initialized.  Time: 19.895319938659668\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = vgg16.VGG16(include_top = True, weights = 'imagenet')\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.outputs = [model.layers[-1].output]\n",
    "end = time.time()\n",
    "print('Neural Network initialized.  Time: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "=================================================================\n",
      "Total params: 117,479,232\n",
      "Trainable params: 117,479,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predictions_ib-0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-50492a398790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0myaml_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_yaml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m  \u001b[0;31m# deletes the existing model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Neural Network saved as YAML.  Time: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mto_yaml\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mYAML\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \"\"\"\n\u001b[0;32m-> 1243\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_updated_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         model_config = {\n\u001b[1;32m   1192\u001b[0m             \u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode_key\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0mnew_node_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_conversion_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_coordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0mmodel_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_node_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predictions_ib-0'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "yaml_model = model.to_yaml()\n",
    "del model  # deletes the existing model\n",
    "end = time.time()\n",
    "print('Neural Network saved as YAML.  Time: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "start = time.time()\n",
    "model = load_model('test_model.h5')\n",
    "end = time.time()\n",
    "print('Neural Network loaded.  Time: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_a = 'data/images/Dino.png'\n",
    "#filename_a = 'data/test1.png'\n",
    "#filename_a = 'data/test2.png'\n",
    "#filename_a = 'data/test3.png'\n",
    "#filename_a = 'data/mossy1.png'\n",
    "#filename_a = 'data/Nibu.png'\n",
    "#filename_a = 'data/dyno.png'\n",
    "#filename_a = 'data/cool.png'\n",
    "\n",
    "# Load image\n",
    "original_a = load_img(filename_a, target_size=(224, 224))\n",
    "print('PIL image size', original_a.size)\n",
    "plt.imshow(original_a)\n",
    "plt.show()\n",
    " \n",
    "# Convert image to numpy array\n",
    "# PIL - image (w, h, channel)  desxxNumpy - image (h, w, channel)\n",
    "numpy_image_a = img_to_array(original_a)\n",
    "plt.imshow(np.uint8(numpy_image_a))\n",
    "plt.show()\n",
    "print('numpy array size',numpy_image_a.shape)\n",
    " \n",
    "# Convert the image into batch format\n",
    "# expand_dims will add an extra dimension to the data at a particular axis\n",
    "# We want the input matrix to the network to be of the form (batchsize, height, width, channels)\n",
    "# Thus we add the extra dimension to the axis 0.\n",
    "image_batch_a = np.expand_dims(numpy_image_a, axis=0)\n",
    "print('image batch size', image_batch_a.shape)\n",
    "plt.imshow(np.uint8(image_batch_a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the image for the VGG model\n",
    "processed_image_a = vgg16.preprocess_input(image_batch_a.copy())\n",
    "\n",
    "# get the predicted probabilities for each class\n",
    "predictions_a = model.predict(processed_image_a)\n",
    "\n",
    "print(predictions_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(predictions_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for vector in vector_list:\n",
    "    labels.append(vector[12:].split('.')[0]+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "score_cos = distance.cdist(predictions_a, feature_matrix, 'cosine').tolist()\n",
    "#score_manhattan = distance.cdist(predictions_a, feature_matrix, 'cityblock').tolist()\n",
    "#score_ham = distance.cdist(predictions_a, feature_matrix, 'hamming').tolist()\n",
    "#score_bc = distance.cdist(predictions_a, feature_matrix, 'braycurtis').tolist()\n",
    "#score_euc = distance.cdist(predictions_a, feature_matrix, 'euclidean').tolist()\n",
    "end = time.time()\n",
    "print('Cosine Similarity with SciPy calculated.  Time: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "score_cos_2 = (predictions_a * feature_matrix)/(LA.norm(predictions_a)*LA.norm(feature_matrix))\n",
    "#distance.cdist(predictions_a, feature_matrix, 'cosine').tolist()\n",
    "\n",
    "end = time.time()\n",
    "print('Cosine Similarity calculated.  Time: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if len(labels) != len(score[0]):\n",
    "#    print('Length mismatch!')\n",
    "\n",
    "sorted_scores = sorted(list(zip(labels,score_cos[0])), key = lambda t: t[1])\n",
    "    \n",
    "for image, score in sorted_scores[0:10]:\n",
    "    url = 'https://s3-us-west-2.amazonaws.com/hole-in-a-bucket/data/'+image\n",
    "    im = Image.open(requests.get(url, stream=True).raw)\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if len(labels) != len(score[0]):\n",
    "#    print('Length mismatch!')\n",
    "\n",
    "sorted_scores_cos_2 = sorted(list(zip(labels,score_cos_2[0])), key = lambda t: t[1])\n",
    "    \n",
    "for image, score in sorted_scores_cos_2[0:10]:\n",
    "    url = 'https://s3-us-west-2.amazonaws.com/hole-in-a-bucket/data/'+image\n",
    "    im = Image.open(requests.get(url, stream=True).raw)\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 - Random\n",
    "\n",
    "for x in range(0,10):\n",
    "    img_name = random.choice(vector_list)[12:].split('.')[0]+'.jpg'\n",
    "    url ='https://s3-us-west-2.amazonaws.com/hole-in-a-bucket/data/'+img_name\n",
    "    im = Image.open(requests.get(url, stream=True).raw)\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df, combined_imgs = load_RG_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'durka.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_test = np.load('data/feature_matrix/fetch_feature_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "idx = 35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if idx>0 and idx<140741:\n",
    "    print(str(idx)+' vectors merged to feature matrix.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if idx%1000 == 0:\n",
    "    print(str(idx)+' vectors merged to feature matrix.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(0,5678,4096)\n",
    "b = np.linspace(340,678,4096)\n",
    "c = np.linspace(40,834789,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durka = np.vstack((feature_matrix_test[0],feature_matrix_test[2],feature_matrix_test[5],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durka.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durka[0] = feature_matrix_test[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_matches(labels,score):\n",
    "    sorted_scores = sorted(list(zip(labels.tolist(),score)), key = lambda t: t[1])\n",
    "    return sorted_scores[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df, combined_imgs = load_RG_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image file name, store in Pandas Series and pickle for website\n",
    "image_names = []\n",
    "for image_url in combined_imgs.ImageUrl[0:140741]:\n",
    "        image_names.append(image_url.split('/')[-1])\n",
    "\n",
    "fetch_image_names = pd.Series(image_names)\n",
    "fetch_image_names.to_pickle('data/fetch_img_urls.pkl', compression='gzip')\n",
    "\n",
    "\n",
    "\n",
    "#combined_df.head()\n",
    "#zipped_dogs = list(zip(dog_url.tolist(),results))\n",
    "#sorted_zipped_dogs = sorted(zipped_dogs, key = lambda t: t[1])\n",
    "#top_10 = sorted_zipped_dogs[0:11]\n",
    "#top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load NumPy data file of 4750 dogs and calculate average number of non-zero features in 1D arrays for all dogs\n",
    "\n",
    "non_zero_features = []\n",
    "feature_array_4750 = np.load('web/static/temp/data/doggie_features_4750.npy')\n",
    "\n",
    "for dog in feature_array_4750:\n",
    "    non_zero_features.append(len(np.where(dog>0)[1]))\n",
    "\n",
    "plt.hist(non_zero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scores in score_lists:\n",
    "    for image,score in top_ten(dog_url, scores):\n",
    "        plt.imshow(load_img('/Users/bil2ab/galvanize/RG5kimages/'+image.split('/')[-1]))\n",
    "        plt.show()\n",
    "        #print(1-score)\n",
    "        #print('DURKA DURKA...next distance metric:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    start = time.time()\n",
    "    feature_array_list = []\n",
    "    #image_path_list formerly combined_df.ImageUrl[0:4750]\n",
    "    for url in image_path_list[0:length]:\n",
    "        image_path = '/Users/bil2ab/galvanize/capstone/images_to_vectorize/images/'+url.split('/')[-1]\n",
    "        dog = load_img(image_path, target_size=(224, 224))\n",
    "        numpy_image = img_to_array(dog)\n",
    "        image_batch = np.expand_dims(numpy_image, axis=0)  \n",
    "        processed_image = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_array = model.predict(processed_image)\n",
    "        feature_array_list.append(feature_array)\n",
    "        #doggie = np.asarray(feature_array_list)\n",
    "        #np.save('data/RG_50k_features', doggie)\n",
    "    end = time.time()\n",
    "    total_time = end-start\n",
    "    print('Total Time: '+str(total_time))\n",
    "    print('All dog features vectorized!')\n",
    "    return feature_array_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url_vec = combined_imgs.ImageUrl.tolist()\n",
    "holy_durka = vectorize_dog_images(url_vec, length=50000)\n",
    "#len(url_50k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def durka():\n",
    "    '''\n",
    "    image_path_list = combined_df.ImageUrl.tolist()\n",
    "    Take collection of dog images and vectorize each image to a 1D NumPy array. \n",
    "    INPUT: List, Pandas Series, some iterable of filepaths to dog images (strings)\n",
    "    OUTPUT: Returns Numpy data file\n",
    "    '''\n",
    "    start = time.time()\n",
    "    combined_df, combined_imgs = load_RG_data()\n",
    "    #num_images = len(glob.glob1('/Users/bil2ab/galvanize/RG5kimages/','*.jpg'))\n",
    "    image_path_list = combined_imgs.ImageUrl.tolist()\n",
    "    feature_matrix = np.zeros((len(image_path_list),4096))\n",
    "    \n",
    "    for idx,url in enumerate(image_path_list):\n",
    "        dog = load_img('/Users/bil2ab/galvanize/RG5kimages/'+url.split('/')[-1], target_size=(224, 224))\n",
    "        image_batch = np.expand_dims(img_to_array(dog), axis=0)  \n",
    "        processed_image = vgg16.preprocess_input(image_batch.copy())\n",
    "        feature_matrix[idx] = model.predict(processed_image)\n",
    "    \n",
    "    #Save csv of image urls\n",
    "    image_path_list.to_csv('/data/dog_urls_test.csv')\n",
    "    \n",
    "    #Save list of feature arrays as numpy data file\n",
    "    #doggie = np.asarray(feature_array_list)\n",
    "    np.save('/data/doggie_features_test', feature_matrix)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Total Time: '+str(end-start))\n",
    "    print('All dog features vectorized!')\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.dot(predictions_a, feature_matrix.T) / (np.linalg.norm(feature_matrix, axis=1) * np.linalg.norm(predictions_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit distance.cdist(predictions_a,feature_matrix,'cosine')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.visualization import visualize_activation\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "\n",
    "# Utility to search for layer index by name.\n",
    "# Alternatively we can specify this as -1 since it corresponds to the last layer.\n",
    "layer_idx = utils.find_layer_idx(model, 'preds')\n",
    "\n",
    "# Swap softmax with linear\n",
    "model.layers[layer_idx].activation = activations.linear\n",
    "model = utils.apply_modifications(model)\n",
    "\n",
    "# This is the output node we want to maximize.\n",
    "filter_idx = 0\n",
    "img = visualize_activation(model, layer_idx, filter_indices=filter_idx)\n",
    "plt.imshow(img[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the VGG model\n",
    "#vgg_model = vgg16.VGG16(weights='imagenet')\n",
    "\n",
    "#Load the Inception_V3 model\n",
    "#inception_model = inception_v3.InceptionV3(weights='imagenet')\n",
    " \n",
    "#Load the ResNet50 model\n",
    "#resnet_model = resnet50.ResNet50(weights='imagenet')\n",
    " \n",
    "#Load the MobileNet model\n",
    "#mobilenet_model = mobilenet.MobileNet(weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full vgg16\n",
    "[<keras.engine.input_layer.InputLayer at 0x1aafbcf2b0>,\n",
    " <keras.layers.convolutional.Conv2D at 0x1ab00d4e80>,\n",
    " <keras.layers.convolutional.Conv2D at 0x1ab00d46d8>,\n",
    " <keras.layers.pooling.MaxPooling2D at 0x1ab0bd20f0>,\n",
    " <keras.layers.convolutional.Conv2D at 0x1aae8eedd8>,\n",
    " <keras.layers.convolutional.Conv2D at 0x1aaf356dd8>,\n",
    " <keras.layers.pooling.MaxPooling2D at 0x1aaf84ac88>,\n",
    " <keras.layers.convolutional.Conv2D at 0x1a7025d550>,\n",
    " <keras.layers.convolutional.Conv2D at 0x1aae42fa90>,\n",
    " <keras.layers.convolutional.Conv2D at 0x1aae8867b8>,\n",
    " <keras.layers.pooling.MaxPooling2D at 0x1aaddc9a58>,\n",
    " <keras.layers.convolutional.Conv2D at 0x1aac093940>,\n",
    " <keras.layers.convolutional.Conv2D at 0x1aaba4e2b0>,\n",
    " <keras.layers.convolutional.Conv2D at 0x1aaa1bccc0>,\n",
    " <keras.layers.pooling.MaxPooling2D at 0x1a6e7e6940>,\n",
    " <keras.layers.convolutional.Conv2D at 0x1a6dafbda0>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb2f0ea0b8>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb2f0ea2b0>,\n",
    " <keras.layers.pooling.MaxPooling2D at 0xb24c75c18>,\n",
    " <keras.layers.core.Flatten at 0xb18b03f28>,\n",
    " <keras.layers.core.Dense at 0xb2f333518>,\n",
    " <keras.layers.core.Dense at 0x1aaa750dd8>,\n",
    " <keras.layers.core.Dense at 0x1ab3fa36d8>]\n",
    "\n",
    "#Original pop off\n",
    "<keras.engine.input_layer.InputLayer at 0xb24363a90>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb24350668>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb17f81da0>,\n",
    " <keras.layers.pooling.MaxPooling2D at 0xb17f81c88>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb18574080>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb18574da0>,\n",
    " <keras.layers.pooling.MaxPooling2D at 0xb18592550>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb185ab898>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb185c7cf8>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb185e23c8>,\n",
    " <keras.layers.pooling.MaxPooling2D at 0xb185fca20>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb18619b70>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb18633ef0>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb1864e3c8>,\n",
    " <keras.layers.pooling.MaxPooling2D at 0xb18665780>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb189c38d0>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb189e0c50>,\n",
    " <keras.layers.convolutional.Conv2D at 0xb189e0f60>,\n",
    " <keras.layers.pooling.MaxPooling2D at 0xb18a0d6d8>,\n",
    " <keras.layers.core.Flatten at 0xb18a2d630>,\n",
    " <keras.layers.core.Dense at 0xb18a2dd30>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract exif data from smartphone image and view in nice format\n",
    "\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "#def extract_image_data(file):\n",
    "filename =''\n",
    "im = PIL.Image.open(filename)\n",
    "exifdict = im._getexif()\n",
    "#print(exifdict)\n",
    "\n",
    "if len(exifdict):\n",
    "    for k in exifdict.keys():\n",
    "        if k in TAGS.keys():\n",
    "            print(TAGS[k], exifdict[k])\n",
    "        else:\n",
    "            print(k, exifdict[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
