{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bil2ab/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from IPython.display import display, Image\n",
    "import urllib.request\n",
    "from PIL.ExifTags import TAGS\n",
    "import PIL.Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_url(pd_series):\n",
    "    '''\n",
    "    Extracts image URLs from the pictures column in the RescuePets database.\n",
    "    INPUT: Pandas Series where each item is a list of dictionaries of dictionaries??\n",
    "    OUTPUT: Pandas dataframe with animalID and imageURL\n",
    "    '''\n",
    "    large_image_urls = []\n",
    "    animalIDs = []\n",
    "        \n",
    "    for lst in pd_series:\n",
    "        for dct in lst:\n",
    "            large_image_urls.append(dct['largeUrl'])\n",
    "                \n",
    "    for url in large_image_urls:\n",
    "        animalIDs.append(url.split('/')[-2])\n",
    "    \n",
    "    return pd.DataFrame({'animalID': animalIDs,'ImageUrl': large_image_urls})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_df(filepath):\n",
    "    '''\n",
    "    Extracts orgId, animalID, name breed and animalLocation from RescueGroup JSON and adds imageURLs\n",
    "    INPUT: JSON filepath, string\n",
    "    OUTPUT: Pandas dataframes\n",
    "    '''\n",
    "    df = pd.read_json(filepath, lines=True)\n",
    "    images = extract_image_url(df.pictures)\n",
    "    df1 = df[['orgID','animalID','name','breed','animalLocation']]\n",
    "    # NOTE: You loose images with this concat\n",
    "    result = pd.concat([df1, images.ImageUrl], axis=1, join_axes=[df1.index])\n",
    "    # Return combined dataframe and original image source dataframe\n",
    "    return result, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(urls):\n",
    "    '''\n",
    "    Downloads all images from Rescue Pets S3 bucket \n",
    "    INPUT: Pandas Series of URLs\n",
    "    OUTPUT: Images stored in data directory.\n",
    "    '''\n",
    "    for image_url in list(urls)[3934:5001]:\n",
    "        image_name = image_url.split('/')[-1]\n",
    "        r = requests.get(image_url, allow_redirects = True)\n",
    "        open('data/images/'+image_name, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557.7937552928925\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "download_images(combined_df.ImageUrl)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Still working on this function\n",
    "def rotate_image(file):\n",
    "    '''\n",
    "    Rotates images uploaded by user's smartphone via exif data.\n",
    "    Images need to be rotated to proper orientation prior to preprocessing step.\n",
    "    '''\n",
    "    image=Image.open(file)\n",
    "    try:\n",
    "        for orientation in ExifTags.TAGS.keys():\n",
    "            if ExifTags.TAGS[orientation]=='Orientation':\n",
    "                break\n",
    "            exif=dict(image._getexif().items())\n",
    "    \n",
    "        if exif[orientation] == 3:\n",
    "            print('Rotate 180 degrees!')\n",
    "            image=image.rotate(180, expand=True)\n",
    "        elif exif[orientation] == 6:\n",
    "            print('Rotate 270 degrees!')\n",
    "            image=image.rotate(270, expand=True)\n",
    "        elif exif[orientation] == 8:\n",
    "            print('Rotate 90 degrees!')\n",
    "            image=image.rotate(90, expand=True)\n",
    "        image.save(file)\n",
    "        image.close()\n",
    "    except (AttributeError, KeyError, IndexError):\n",
    "    # cases: image don't have getexif   \n",
    "        pass\n",
    "    return(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract exif data from smartphone image and view in nice format\n",
    "\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "#def extract_image_data(file):\n",
    "filename =''\n",
    "im = PIL.Image.open(filename)\n",
    "exifdict = im._getexif()\n",
    "#print(exifdict)\n",
    "\n",
    "if len(exifdict):\n",
    "    for k in exifdict.keys():\n",
    "        if k in TAGS.keys():\n",
    "            print(TAGS[k], exifdict[k])\n",
    "        else:\n",
    "            print(k, exifdict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_pets_df = pd.read_json('data/h9DH7711_newpets_1.json', lines=True)\n",
    "#pets1_df = pd.read_json('data/h9DH7711_pets_1.json', lines=True)\n",
    "#pets2_df = pd.read_json('data/h9DH7711_pets_2.json', lines=True)\n",
    "#pets3_df = pd.read_json('data/h9DH7711_pets_3.json', lines=True)\n",
    "#pets4_df = pd.read_json('data/h9DH7711_pets_4.json', lines=True)\n",
    "#pets5_df = pd.read_json('data/h9DH7711_pets_5.json', lines=True)\n",
    "\n",
    "#import pdb \n",
    "#pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0, image0 = extract_df('data/h9DH7711_newpets_1.json')\n",
    "df1, image1 = extract_df('data/h9DH7711_pets_1.json')\n",
    "df2, image2 = extract_df('data/h9DH7711_pets_2.json')\n",
    "df3, image3 = extract_df('data/h9DH7711_pets_3.json')\n",
    "df4, image4 = extract_df('data/h9DH7711_pets_4.json')\n",
    "df5, image5 = extract_df('data/h9DH7711_pets_5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = df0.append([df1, df2, df3, df4, df5])\n",
    "combined_imgs = image0.append([image1, image2, image3, image4, image5])\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "combined_imgs = combined_imgs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records:  49755\n",
      "Total Images:  143562\n"
     ]
    }
   ],
   "source": [
    "total_records = [df0.shape[0], df1.shape[0], df2.shape[0], df3.shape[0], df4.shape[0], df5.shape[0]]\n",
    "image_records = [image0.shape[0], image1.shape[0], image2.shape[0], image3.shape[0], image4.shape[0], image5.shape[0]]\n",
    "print('Total Records: ',sum(total_records))\n",
    "print('Total Images: ',sum(image_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animalID</th>\n",
       "      <th>ImageUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13398118</td>\n",
       "      <td>https://s3.amazonaws.com/filestore.rescuegroup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13398123</td>\n",
       "      <td>https://s3.amazonaws.com/filestore.rescuegroup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13398123</td>\n",
       "      <td>https://s3.amazonaws.com/filestore.rescuegroup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13398132</td>\n",
       "      <td>https://s3.amazonaws.com/filestore.rescuegroup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13398133</td>\n",
       "      <td>https://s3.amazonaws.com/filestore.rescuegroup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   animalID                                           ImageUrl\n",
       "0  13398118  https://s3.amazonaws.com/filestore.rescuegroup...\n",
       "1  13398123  https://s3.amazonaws.com/filestore.rescuegroup...\n",
       "2  13398123  https://s3.amazonaws.com/filestore.rescuegroup...\n",
       "3  13398132  https://s3.amazonaws.com/filestore.rescuegroup...\n",
       "4  13398133  https://s3.amazonaws.com/filestore.rescuegroup..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combined_df.columns\n",
    "#combined_imgs.columns\n",
    "combined_imgs.head()\n",
    "#combined_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.amazonaws.com/filestore.rescuegroups.org/704/pictures/animals/6482/6482925/38852933_500x375.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_imgs.ImageUrl.values[6574]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns to drop?: 'petUrl','drools' \n",
    "#Columns to rename?: animalLocation to zipcode use GeoPy to get city and state? \n",
    "#Activity Level change to scale from 1 to 4?\n",
    "#Age change to numeric scale from 1 to 4 for Baby, Young, Adult, Senior? '' = UNK?\n",
    "#'apartment', 'cratetrained', 'declawed' change to numeric 0,1=yes\n",
    "#'birthdate' to get exact age? lot of nulls\n",
    "#'breed','color', 'descriptionPlain'...tokenize with NLP? Combine them?\n",
    "#'eventempered',eagerToPlease','cats','dogs' good with cats or dogs?, change to numeric? 0,1,2=UNK\n",
    "#'coatLength' Med, Short, Long, ''=UNK\n",
    "#'contactEmail' & 'contactCellPhone'=='contactHomePhone' drop? only 1 seen in new Dog JSON...only drop after merging all JSONs!!\n",
    "#'contactName' foster? drop?\n",
    "#'exerciseNeeds' Low, Moderate, High, Not Required, ''=UNK...combine with activity level?\n",
    "#'description' == 'trackerImageUrl'\n",
    "#'eyeColor' various string descriptions lot of blanks.. merge to description?\n",
    "#'fence'..Not Required, Any Type, 3ft or 6ft\n",
    "#Need more info on following columns: 'altered','courtesy','lastUpdated','mediaLastUpdated','MessagePet'\n",
    "\n",
    "#df[df['eyeColor']==''].count()\n",
    "#df.activityLevel.isnull().count()\n",
    "#df[df['earType']==''].count()\n",
    "#type(df.breed[10])\n",
    "#df.shape\n",
    "#df.eagerToPlease.unique()\n",
    "#df.pictures[698]\n",
    "new_pets_df.pictures[1]\n",
    "#df.name[df.name == 'Atlas']\n",
    "#df.animalLocation[df.animalLocation ==\"90018\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_df[combined_df.animalLocation == \n",
    "#type(combined_df.animalLocation[0])\n",
    "\n",
    "wa_zip_string = ''\n",
    "\n",
    "\n",
    "\n",
    "sea_zips = [98101, 98102, 98103, 98104, 98105, 98106, 98107, 98108, 98109, 98112, 98115, 98116, 98117, 98118, 98119, 98121, 98122, 98125, 98126, 98133, 98134, 98136, 98144, 98146, 98154, 98164, 98174, 98177, 98178, 98195, 98199]\n",
    "\n",
    "seattle_zips = []\n",
    "for zip in sea_zips:\n",
    "    seattle_zips.append(str(zip))\n",
    "\n",
    "seattle_df = combined_df.loc[combined_df.animalLocation.isin(seattle_zips)]\n",
    "\n",
    "cool = seattle_df.animalID.tolist()\n",
    "cool_df = combined_df.loc[combined_df.animalID.isin(cool)]\n",
    "\n",
    "#cool_df.ImageUrl\n",
    "\n",
    "#seattle_dog_imgs = cool_df.ImageUrl.tolist()\n",
    "#len(seattle_dog_imgs)\n",
    "\n",
    "len(combined_df.ImageUrl.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_array(imgURLs):\n",
    "    \n",
    "    for url in imgURLs:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def zip_lookup(zip_code):\n",
    "    geolocator = Nominatim()\n",
    "    location = geolocator.geocode(zip_code)\n",
    "    city = location.address.split(',')[0].strip()\n",
    "    state = location.address.split(',')[1].strip()\n",
    "    return city, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.scatter_matrix(df, alpha=0.2, diagonal='kde', figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pymongo\n",
    "\n",
    "mc = pymongo.MongoClient()\n",
    "scraper_db = mc['scraper']\n",
    "sites = scraper_db['sites']\n",
    "sites.delete_many({})\n",
    "\n",
    "\n",
    "def retrieve_site(url:str) -> bytes:\n",
    "    for site in sites.find():\n",
    "        if site['url'] == url:\n",
    "            return site['data']\n",
    "\n",
    "        \n",
    "def scrape_site(url:str) -> bytes:\n",
    "    data = retrieve_site(url)\n",
    "    if data:\n",
    "        return data\n",
    "    response = requests.get(url)\n",
    "    data = response.content\n",
    "    sites.insert_one({'url': url,'data': data})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.ImageUrl[1370:5001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
