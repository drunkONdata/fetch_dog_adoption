{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from IPython.display import display, Image\n",
    "import urllib.request\n",
    "from PIL.ExifTags import TAGS\n",
    "import PIL.Image\n",
    "import time\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.spatial import distance\n",
    "import random\n",
    "import time\n",
    "import urllib.request\n",
    "import io\n",
    "import glob\n",
    "\n",
    "from src.fetch_data_pipeline import extract_image_url, extract_df, download_images, load_RG_data, zip_lookup, gps_lookup\n",
    "import json\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_url(pd_series):\n",
    "    '''\n",
    "    Extracts image URLs from the pictures column in the RescuePets database.\n",
    "    INPUT: Pandas Series where each item is a list of dictionaries of dictionaries??\n",
    "    OUTPUT: Pandas dataframe with animalID and imageURL\n",
    "    '''\n",
    "    large_image_urls = []\n",
    "    animalIDs = []\n",
    "        \n",
    "    for lst in pd_series:\n",
    "        for dct in lst:\n",
    "            large_image_urls.append(dct['largeUrl'])\n",
    "                \n",
    "    for url in large_image_urls:\n",
    "        animalIDs.append(url.split('/')[-2])\n",
    "    \n",
    "    return pd.DataFrame({'animalID': animalIDs,'ImageUrl': large_image_urls})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_df(filepath):\n",
    "    '''\n",
    "    Extracts orgId, animalID, name breed and animalLocation from RescueGroup JSON and adds imageURLs\n",
    "    INPUT: JSON filepath, string\n",
    "    OUTPUT: Pandas dataframes\n",
    "    '''\n",
    "    df = pd.read_json(filepath, lines=True)\n",
    "    images = extract_image_url(df.pictures)\n",
    "    df1 = df[['orgID','animalID','name','breed','animalLocation']]\n",
    "    # NOTE: You loose images with this concat\n",
    "    result = pd.concat([df1, images.ImageUrl], axis=1, join_axes=[df1.index])\n",
    "    # Return combined dataframe and original image source dataframe\n",
    "    return result, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(urls):\n",
    "    '''\n",
    "    Downloads all images from Rescue Pets S3 bucket \n",
    "    INPUT: Pandas Series of URLs\n",
    "    OUTPUT: Images stored in data directory.\n",
    "    '''\n",
    "    for image_url in list(urls)[3934:5001]:\n",
    "        image_name = image_url.split('/')[-1]\n",
    "        r = requests.get(image_url, allow_redirects = True)\n",
    "        open('data/images/'+image_name, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "download_images(combined_df.ImageUrl)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Still working on this function\n",
    "def rotate_image(file):\n",
    "    '''\n",
    "    Rotates images uploaded by user's smartphone via exif data.\n",
    "    Images need to be rotated to proper orientation prior to preprocessing step.\n",
    "    '''\n",
    "    image=Image.open(file)\n",
    "    try:\n",
    "        for orientation in ExifTags.TAGS.keys():\n",
    "            if ExifTags.TAGS[orientation]=='Orientation':\n",
    "                break\n",
    "            exif=dict(image._getexif().items())\n",
    "    \n",
    "        if exif[orientation] == 3:\n",
    "            print('Rotate 180 degrees!')\n",
    "            image=image.rotate(180, expand=True)\n",
    "        elif exif[orientation] == 6:\n",
    "            print('Rotate 270 degrees!')\n",
    "            image=image.rotate(270, expand=True)\n",
    "        elif exif[orientation] == 8:\n",
    "            print('Rotate 90 degrees!')\n",
    "            image=image.rotate(90, expand=True)\n",
    "        image.save(file)\n",
    "        image.close()\n",
    "    except (AttributeError, KeyError, IndexError):\n",
    "    # cases: image don't have getexif   \n",
    "        pass\n",
    "    return(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract exif data from smartphone image and view in nice format\n",
    "\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "#def extract_image_data(file):\n",
    "filename =''\n",
    "im = PIL.Image.open(filename)\n",
    "exifdict = im._getexif()\n",
    "#print(exifdict)\n",
    "\n",
    "if len(exifdict):\n",
    "    for k in exifdict.keys():\n",
    "        if k in TAGS.keys():\n",
    "            print(TAGS[k], exifdict[k])\n",
    "        else:\n",
    "            print(k, exifdict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_pets_df = pd.read_json('data/h9DH7711_newpets_1.json', lines=True)\n",
    "#pets1_df = pd.read_json('data/h9DH7711_pets_1.json', lines=True)\n",
    "#pets2_df = pd.read_json('data/h9DH7711_pets_2.json', lines=True)\n",
    "#pets3_df = pd.read_json('data/h9DH7711_pets_3.json', lines=True)\n",
    "#pets4_df = pd.read_json('data/h9DH7711_pets_4.json', lines=True)\n",
    "#pets5_df = pd.read_json('data/h9DH7711_pets_5.json', lines=True)\n",
    "\n",
    "#import pdb \n",
    "#pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0, image0 = extract_df('data/h9DH7711_newpets_1.json')\n",
    "df1, image1 = extract_df('data/h9DH7711_pets_1.json')\n",
    "df2, image2 = extract_df('data/h9DH7711_pets_2.json')\n",
    "df3, image3 = extract_df('data/h9DH7711_pets_3.json')\n",
    "df4, image4 = extract_df('data/h9DH7711_pets_4.json')\n",
    "df5, image5 = extract_df('data/h9DH7711_pets_5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = df0.append([df1, df2, df3, df4, df5])\n",
    "combined_imgs = image0.append([image1, image2, image3, image4, image5])\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "combined_imgs = combined_imgs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_records = [df0.shape[0], df1.shape[0], df2.shape[0], df3.shape[0], df4.shape[0], df5.shape[0]]\n",
    "image_records = [image0.shape[0], image1.shape[0], image2.shape[0], image3.shape[0], image4.shape[0], image5.shape[0]]\n",
    "print('Total Records: ',sum(total_records))\n",
    "print('Total Images: ',sum(image_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_df.columns\n",
    "#combined_imgs.columns\n",
    "combined_imgs.head()\n",
    "#combined_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_imgs.ImageUrl.values[6574]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns to drop?: 'petUrl','drools' \n",
    "#Columns to rename?: animalLocation to zipcode use GeoPy to get city and state? \n",
    "#Activity Level change to scale from 1 to 4?\n",
    "#Age change to numeric scale from 1 to 4 for Baby, Young, Adult, Senior? '' = UNK?\n",
    "#'apartment', 'cratetrained', 'declawed' change to numeric 0,1=yes\n",
    "#'birthdate' to get exact age? lot of nulls\n",
    "#'breed','color', 'descriptionPlain'...tokenize with NLP? Combine them?\n",
    "#'eventempered',eagerToPlease','cats','dogs' good with cats or dogs?, change to numeric? 0,1,2=UNK\n",
    "#'coatLength' Med, Short, Long, ''=UNK\n",
    "#'contactEmail' & 'contactCellPhone'=='contactHomePhone' drop? only 1 seen in new Dog JSON...only drop after merging all JSONs!!\n",
    "#'contactName' foster? drop?\n",
    "#'exerciseNeeds' Low, Moderate, High, Not Required, ''=UNK...combine with activity level?\n",
    "#'description' == 'trackerImageUrl'\n",
    "#'eyeColor' various string descriptions lot of blanks.. merge to description?\n",
    "#'fence'..Not Required, Any Type, 3ft or 6ft\n",
    "#Need more info on following columns: 'altered','courtesy','lastUpdated','mediaLastUpdated','MessagePet'\n",
    "\n",
    "#df[df['eyeColor']==''].count()\n",
    "#df.activityLevel.isnull().count()\n",
    "#df[df['earType']==''].count()\n",
    "#type(df.breed[10])\n",
    "#df.shape\n",
    "#df.eagerToPlease.unique()\n",
    "#df.pictures[698]\n",
    "new_pets_df.pictures[1]\n",
    "#df.name[df.name == 'Atlas']\n",
    "#df.animalLocation[df.animalLocation ==\"90018\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_df[combined_df.animalLocation == \n",
    "#type(combined_df.animalLocation[0])\n",
    "\n",
    "wa_zip_string = ''\n",
    "\n",
    "\n",
    "\n",
    "sea_zips = [98101, 98102, 98103, 98104, 98105, 98106, 98107, 98108, 98109, 98112, 98115, 98116, 98117, 98118, 98119, 98121, 98122, 98125, 98126, 98133, 98134, 98136, 98144, 98146, 98154, 98164, 98174, 98177, 98178, 98195, 98199]\n",
    "\n",
    "seattle_zips = []\n",
    "for zip in sea_zips:\n",
    "    seattle_zips.append(str(zip))\n",
    "\n",
    "seattle_df = combined_df.loc[combined_df.animalLocation.isin(seattle_zips)]\n",
    "\n",
    "cool = seattle_df.animalID.tolist()\n",
    "cool_df = combined_df.loc[combined_df.animalID.isin(cool)]\n",
    "\n",
    "#cool_df.ImageUrl\n",
    "\n",
    "#seattle_dog_imgs = cool_df.ImageUrl.tolist()\n",
    "#len(seattle_dog_imgs)\n",
    "\n",
    "len(combined_df.ImageUrl.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def zip_lookup(zip_code):\n",
    "    geolocator = Nominatim()\n",
    "    location = geolocator.geocode(zip_code)\n",
    "    city = location.address.split(',')[0].strip()\n",
    "    state = location.address.split(',')[1].strip()\n",
    "    return city, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.scatter_matrix(df, alpha=0.2, diagonal='kde', figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.ImageUrl[5000].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.applications import vgg16, inception_v3, resnet50, mobilenet\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "results = []\n",
    "\n",
    "model = vgg16.VGG16(include_top = True, weights = 'imagenet')\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.outputs = [model.layers[-1].output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in combined_df.ImageUrl[0:50]:\n",
    "    image_path = 'data/images/'+url.split('/')[-1]\n",
    "    dog = load_img(image_path, target_size=(224, 224))\n",
    "    numpy_image = img_to_array(dog)\n",
    "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
    "   \n",
    "    processed_image = vgg16.preprocess_input(image_batch.copy())\n",
    "    feature_array = model.predict(processed_image)\n",
    "    \n",
    "    cosine_score = distance.cosine(feature_array.flatten(), durka.flatten())\n",
    "    results.append(cosine_score)\n",
    "\n",
    "dog_url = combined_df.ImageUrl[0:50]\n",
    "zipped_dogs = zip(dog_url.tolist(),results)\n",
    "sorted_zipped_dogs = zipped_dogs.sort(key = lambda t: t[1])\n",
    "top_10 = sorted_zipped_dogs[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imgURL in \n",
    "\n",
    "image_name = image_url.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "import urllib.request\n",
    "import io\n",
    "\n",
    "from src.fetch_data_pipeline import extract_image_url, extract_df, download_images, load_RG_data, zip_lookup, gps_lookup\n",
    "import json\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records:  49755\n",
      "Total Images:  143562\n"
     ]
    }
   ],
   "source": [
    "combined_df, combined_imgs = load_RG_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16.VGG16(include_top = True, weights = 'imagenet')\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model.outputs = [model.layers[-1].output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "durka\n",
      "durka\n",
      "durka\n",
      "durka\n",
      "durka\n",
      "durka\n",
      "durka\n",
      "durka\n",
      "durka\n",
      "durka\n",
      "Total Time: 19.263476848602295\n",
      "All dog features vectorized!\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "feature_list = []\n",
    "feature_matrix = np.zeros((4096,10))\n",
    "\n",
    "for url in combined_imgs.ImageUrl.tolist()[0:10]:\n",
    "    dog = load_img('/Users/bil2ab/galvanize/RG5kimages/'+url.split('/')[-1], target_size=(224, 224))\n",
    "    numpy_image = img_to_array(dog)\n",
    "    image_batch = np.expand_dims(numpy_image, axis=0)  \n",
    "    processed_image = vgg16.preprocess_input(image_batch.copy())\n",
    "    feature_array = model.predict(processed_image)\n",
    "    #np.insert()\n",
    "    feature_list.append(feature_array)\n",
    "    print('durka')\n",
    "    #doggie = np.asarray(feature_array_list)\n",
    "    #np.save('data/RG_features', doggie)\n",
    "end = time.time()\n",
    "total_time = end-start\n",
    "print('Total Time: '+str(total_time))\n",
    "print('All dog features vectorized!')\n",
    "result = np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/test',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deque method 100 iterations ~211.706 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/test2',feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
